{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Machine Learning with Text in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "1. Model building in scikit-learn (refresher)\n",
    "2. Representing text as numerical data\n",
    "3. Reading a text-based dataset into pandas\n",
    "4. Vectorizing our dataset\n",
    "5. Building and evaluating a model\n",
    "6. Comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Python 2: to use print()  as a function, \n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Model building in scikit-learn (refresher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the iris dataset as an example\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# store the feature matrix (X) and response vector (y)\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "print(type(X),type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"Features\"** are also known as predictors, inputs, or attributes. The **\"response\"** is also known as the target, label, or output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "# check the shapes of X and y\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"Observations\"** are also known as samples, instances, or records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the first 5 rows of the feature matrix (including the feature names)\n",
    "import pandas as pd\n",
    "pd.DataFrame(X, columns=iris.feature_names).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# examine the response vector\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to **build a model**, the features must be **numeric**, and every observation must have the **same features in the same order**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the class\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# instantiate the model (with the default parameters)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# fit the model with data (occurs in-place)\n",
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # by default split by 75% and 25%\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  0,  0],\n",
       "       [ 0, 15,  0],\n",
       "       [ 0,  0, 12]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1158c71d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import scikitplot as skplt\n",
    "        \n",
    "skplt.metrics.plot_confusion_matrix(y_test, y_pred, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to **make a prediction**, the new observation must have the **same features as the training observations**, both in number and meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Representing text as numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example text for model training (SMS messages)\n",
    "simple_train = ['call you tonight', 'Call me a cab', 'please call me... PLEASE!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example response vector\n",
    "is_desperate = [0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> Text Analysis is a major application field for machine learning algorithms. However the raw data, a sequence of symbols cannot be fed directly to the algorithms themselves as most of them expect **numerical feature vectors with a fixed size** rather than the **raw text documents with variable length**.\n",
    "\n",
    "We will use [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to \"convert text into a matrix of token counts\":\n",
    "\n",
    "### note - Vectorizer has  4 steps as ML\n",
    "    * Import\n",
    "    * Instantiate\n",
    "    * Fit\n",
    "    * Transform ( in place of predict in ml model)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate CountVectorizer (with the default parameters)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train to get  the 'vocabulary' of the training data (occurs in-place)\n",
    "vect.fit(simple_train)\n",
    "\n",
    "# WE CAN PASS STOPWORDS list in stop_words option,\n",
    "# it will automatically ignore all the words having length less than 2, we can change that in token_pattern parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cab', 'call', 'me', 'please', 'tonight', 'you']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the fitted vocabulary\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform training data into a 'document-term matrix'\n",
    "# first time we pass to fit, now pass to get the vector for each document\n",
    "simple_train_dtm = vect.transform(simple_train)\n",
    "simple_train_dtm\n",
    "# 3*6 document term matrix, as we have 3 rows and total 6 features we got from vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 2, 0, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert sparse matrix to a dense matrix\n",
    "simple_train_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   0       0        1    1\n",
       "1    1     1   1       0        0    0\n",
       "2    0     1   1       2        0    0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(simple_train_dtm.toarray(), columns=vect.get_feature_names())\n",
    "\n",
    "# this is called BAG OF WORDS strategy where we count presense of each word "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> In this scheme, features and samples are defined as follows:\n",
    "\n",
    "> - Each individual token occurrence frequency (normalized or not) is treated as a **feature**.\n",
    "> - The vector of all the token frequencies for a given document is considered a multivariate **sample**.\n",
    "\n",
    "> A **corpus of documents** can thus be represented by a matrix with **one row per document** and **one column per token** (e.g. word) occurring in the corpus.\n",
    "\n",
    "> We call **vectorization** the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the **Bag of Words** or \"Bag of n-grams\" representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the type of the document-term matrix\n",
    "type(simple_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 3)\t2\n"
     ]
    }
   ],
   "source": [
    "# examine the sparse matrix contents (i,j) -> value ( if present in sparse matrix )\n",
    "print(simple_train_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> As most documents will typically use a very small subset of the words used in the corpus, the resulting matrix will have **many feature values that are zeros** (typically more than 99% of them).\n",
    "\n",
    "> For instance, a collection of 10,000 short text documents (such as emails) will use a vocabulary with a size in the order of 100,000 unique words in total while each document will use 100 to 1000 unique words individually.\n",
    "\n",
    "> In order to be able to **store such a matrix in memory** but also to **speed up operations**, implementations will typically use a **sparse representation** such as the implementations available in the `scipy.sparse` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a model to predict desperation\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(simple_train_dtm, is_desperate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example text for model testing\n",
    "simple_test = [\"please don't call me\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to **make a prediction**, the new observation must have the **same features as the training observations**, both in number and meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data into a document-term matrix (using existing vocabulary)\n",
    "simple_test_dtm = vect.transform(simple_test)\n",
    "simple_test_dtm.toarray()\n",
    "\n",
    "# note - when we transform() for test documents, we  only get value for the words, which were there in train documents.\n",
    "# if word  is not in training then it will be ignored by transform(), like \"don't\" ignored in following example\n",
    "# and its completely okay as model doesn't know the relationship between \"don't\" and \"classToPredict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   1       1        0    0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(simple_test_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict whether simple_test is desperate\n",
    "knn.predict(simple_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confidence of each class\n",
    "knn.predict_proba(simple_test_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "\n",
    "- `vect.fit(train)` **learns the vocabulary** of the training data\n",
    "- `vect.transform(train)` uses the **fitted vocabulary** to build a document-term matrix from the training data\n",
    "- `vect.transform(test)` uses the **fitted vocabulary** to build a document-term matrix from the testing data (and **ignores tokens** it hasn't seen before)\n",
    "\n",
    "### Note - we can also use vect.fit_transform(train) as it will fit and return back dtm in one step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Reading a text-based dataset into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file into pandas from the working directory\n",
    "sms = pd.read_table('sms.tsv', header=None, names=['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative: read file into pandas from a URL\n",
    "# url = 'https://raw.githubusercontent.com/justmarkham/pydata-dc-2016-tutorial/master/sms.tsv'\n",
    "# sms = pd.read_table(url, header=None, names=['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the shape\n",
    "sms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the first 10 rows\n",
    "sms.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the class distribution\n",
    "sms.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert label to a numerical variable\n",
    "sms['label_num'] = sms.label.map({'ham':0, 'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  label_num\n",
       "0   ham  Go until jurong point, crazy.. Available only ...          0\n",
       "1   ham                      Ok lar... Joking wif u oni...          0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...          1\n",
       "3   ham  U dun say so early hor... U c already then say...          0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...          0\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...          1\n",
       "6   ham  Even my brother is not like to speak with me. ...          0\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...          0\n",
       "8  spam  WINNER!! As a valued network customer you have...          1\n",
       "9  spam  Had your mobile 11 months or more? U R entitle...          1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the conversion worked\n",
    "sms.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "# how to define X and y (from the iris data) for use with a MODEL\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572,)\n",
      "(5572,)\n"
     ]
    }
   ],
   "source": [
    "# how to define X and y (from the SMS data) for use with COUNTVECTORIZER\n",
    "# vectorizer will convert 1d to 2d data when counting the occurances\n",
    "X = sms.message\n",
    "y = sms.label_num\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4179,)\n",
      "(1393,)\n",
      "(4179,)\n",
      "(1393,)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Vectorizing our dataset\n",
    "\n",
    "### Why Splitting before Vectorizing dataset?\n",
    "In real world we might see different data for our test set, thats why to simulate this in validation, we split before doing Vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the vectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalently: combine fit and transform into a single step\n",
    "X_train_dtm = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4179x7456 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 55209 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the document-term matrix\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1393x7456 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 17604 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Building and evaluating a model\n",
    "\n",
    "We will use [multinomial Naive Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html):\n",
    "\n",
    "> The multinomial Naive Bayes classifier is suitable for classification with **discrete features** (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.89 ms, sys: 2.98 ms, total: 8.87 ms\n",
      "Wall time: 6.19 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "%time nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9885139985642498"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1203,    5],\n",
       "       [  11,  174]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print message text for the false positives (ham incorrectly classified as spam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print message text for the false negatives (spam incorrectly classified as ham)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LookAtMe!: Thanks for your purchase of a video clip from LookAtMe!, you've been charged 35p. Think you can do better? Why not send a video in a MMSto 32323.\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example false negative\n",
    "X_test[3132]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.87744864e-03, 1.83488846e-05, 2.07301295e-03, ...,\n",
       "       1.09026171e-06, 1.00000000e+00, 3.98279868e-09])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities for X_test_dtm (poorly calibrated)\n",
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9866431000536962"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Comparing models\n",
    "\n",
    "We will compare multinomial Naive Bayes with [logistic regression](http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression):\n",
    "\n",
    "> Logistic regression, despite its name, is a **linear model for classification** rather than regression. Logistic regression is also known in the literature as logit regression, maximum-entropy classification (MaxEnt) or the log-linear classifier. In this model, the probabilities describing the possible outcomes of a single trial are modeled using a logistic function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.2 ms, sys: 3.73 ms, total: 48.9 ms\n",
      "Wall time: 48.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm\n",
    "%time logreg.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = logreg.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01269556, 0.00347183, 0.00616517, ..., 0.03354907, 0.99725053,\n",
       "       0.00157706])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities for X_test_dtm (well calibrated)\n",
    "y_pred_prob = logreg.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9877961234745154"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9936817612314301"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
